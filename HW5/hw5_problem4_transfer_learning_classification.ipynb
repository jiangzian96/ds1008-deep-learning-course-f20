{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw5_problem4_transfer_learning_classification_zj444.ipynb","provenance":[{"file_id":"1n-sYOqkzQBifc-s4y41Dm2LHjIJ2Tfgn","timestamp":1605575025684},{"file_id":"1aXtusdQsXNGUwkmtnqFOHH34TinD7j8o","timestamp":1605283048552},{"file_id":"https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb","timestamp":1604973155173}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"a4bc9bc89df8471c882e44493dc1d52a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7468d4c6a2cb4a409dd8544d433b157b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e0056e179cae4b418016c1bd5beb02a5","IPY_MODEL_51e31c61ea1943c2935b9dd0f7cd6ff8"]}},"7468d4c6a2cb4a409dd8544d433b157b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0056e179cae4b418016c1bd5beb02a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3cc8d4d93d6c4aa9bc1fecb703b20d0a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9076a12a2ab54f39a5b0ff0f3fdc2234"}},"51e31c61ea1943c2935b9dd0f7cd6ff8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f19ff059c6434a9fbf809ef302a93ad4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:34&lt;00:00, 12.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_64951f215e4e455e9f7af46385f802fb"}},"3cc8d4d93d6c4aa9bc1fecb703b20d0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9076a12a2ab54f39a5b0ff0f3fdc2234":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f19ff059c6434a9fbf809ef302a93ad4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"64951f215e4e455e9f7af46385f802fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sRRA4H5UaiN5"},"source":["# Problem 4\n","\n","In this problem, we simply finetune a BERT model (not pretrained) on RTE dataset, and then finetune a BERT model (pretrained) on RTE dataset.\n","\n","**IMPORTANT NOTES**:\n","- Please make sure that you have already read the part of hw5 pdf that corresponds to this problem. This is very important.\n","- At the end of the hw5, you will need to submit a zip folder containing three things. The instruction is also included in the first paragraph of the hw5 pdf.\n","  - (1) The writeup pdf containing your solutions to Problems 1, 2, 3, 4, 5. Yes, there're things you need to respond in your writeup (see hw5 pdf).\n","  - (2) The downloaded colab corresponding to Problem 4.\n","  - (3) The downloaded colab corresponding to Problem 5."]},{"cell_type":"markdown","metadata":{"id":"tPcxZxOfGnMO"},"source":["Some imports and data downloading"]},{"cell_type":"code","metadata":{"id":"4prQ5aWt20vn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605746555112,"user_tz":300,"elapsed":3054,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"7ba47829-52fb-4f6f-8f8c-b5f1430fdfa9"},"source":["!git clone https://github.com/huggingface/transformers\n","!python transformers/utils/download_glue_data.py --tasks RTE\n","!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'transformers' already exists and is not an empty directory.\n","Downloading and extracting RTE...\n","\tCompleted!\n","Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n","Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Mll62bB2-g3"},"source":["import dataclasses\n","import logging\n","import os\n","import sys\n","from dataclasses import dataclass, field\n","from typing import Dict, Optional\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F\n","from transformers import AutoTokenizer, EvalPrediction, GlueDataset, GlueDataTrainingArguments, AutoModel, BertPreTrainedModel, AutoConfig, BertModel\n","from transformers import GlueDataTrainingArguments \n","from transformers import (\n","    Trainer,\n","    TrainingArguments,\n","    glue_compute_metrics,\n","    glue_tasks_num_labels,\n","    set_seed,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CE3DrrKCfDAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605746555253,"user_tz":300,"elapsed":1711,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"b6c3b2d2-256d-4608-d7d9-d45793897be1"},"source":["!ls glue_data/RTE/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cached_dev_BertTokenizer_128_rte\t dev.tsv\n","cached_dev_BertTokenizer_128_rte.lock\t test.tsv\n","cached_train_BertTokenizer_128_rte\t train.tsv\n","cached_train_BertTokenizer_128_rte.lock\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I1TiFjM93SOf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605746559170,"user_tz":300,"elapsed":212,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"70346ed1-7098-452b-bb84-23f4628517c4"},"source":["model_name = \"bert-base-uncased\"\n","\n","data_args = GlueDataTrainingArguments(task_name=\"rte\", data_dir=\"./glue_data/RTE\")\n","training_args = TrainingArguments(\n","    logging_steps=50, \n","    per_device_train_batch_size=32, \n","    per_device_eval_batch_size=64, \n","    save_steps=1000,\n","    evaluate_during_training=True,\n","    output_dir=\"./models/rte\",\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    do_predict=True,\n","    learning_rate=0.00001,\n","    num_train_epochs=15,\n",")\n","\n","num_labels = glue_tasks_num_labels[data_args.task_name]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"93lLGbD1G3pE"},"source":["### From non-pretrained BERT"]},{"cell_type":"markdown","metadata":{"id":"2R-0NnqSub6G"},"source":["TODO:\n","- Complete the following three lines such that ```tokenizer``` and ```config``` and ```bert_model``` corresponds to the ```model_name``` we defined in the above cells. \n","- IMPORTANT: make sure that the BERT model does not load pretrained weights!\n","- Hint: https://huggingface.co/transformers/model_doc/auto.html and other relevant Hugging Face documentations. Consider using the tools we imported in the first cell. More hints: it's okay to use ```from_pretrained``` in the first two lines, depending on what class you use."]},{"cell_type":"code","metadata":{"id":"AAIHYGLTsJ-a"},"source":["tokenizer =  AutoTokenizer.from_pretrained(model_name)\n","config = AutoConfig.from_pretrained(model_name)\n","bert_model = AutoModel.from_config(config)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XcY-AENpsy2H"},"source":["TODO:\n","- Complete the forward function of the following class such that the model can do finetuning on RTE dataset.\n","- For more instructions, please refer to the hw5 pdf."]},{"cell_type":"code","metadata":{"id":"EwLCrHQiG6fz"},"source":["class SequenceClassificationBERT(nn.Module):\n","      \n","    def __init__(self, config, bert_model):\n","        super().__init__()\n","        self.config = config\n","        self.num_labels = config.num_labels\n","        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n","        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n","        self.bert = bert_model\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","        output_attentions=None,\n","        output_hidden_states=None,\n","        return_dict=None,\n","    ):\n","        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n","\n","        # make sure that all the arguments in the forward() function is used\n","        # somewhere in the code\n","\n","        ##### \n","        #input_ids = input_ids.cuda()\n","        #labels = labels.cuda()\n","        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, position_ids=position_ids, head_mask=head_mask,\\\n","                            inputs_embeds=inputs_embeds, encoder_hidden_states=None, encoder_attention_mask=None, output_attentions=output_attentions, \\\n","                            output_hidden_states=output_hidden_states, return_dict=return_dict)\n","        last_hidden_states = outputs[0]\n","        pooler_outputs = outputs[1]\n","        logits = self.classifier(pooler_outputs)\n","        loss = F.binary_cross_entropy_with_logits(logits[:, 1], labels.float())\n","        #####\n","        # do not change the lines below, so make sure your code works for the\n","        # lines below\n","        output = (logits,) + outputs[2:]\n","        return ((loss,) + output) if loss is not None else output\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pw3Uy5Bvrwk0"},"source":["TODO:\n","- Print out the number of trainable parameters in the BERT model. This can be done in one line. Please feel free to look up resources online. We also briefly touched upon relevant materials in Lab 3, but here, make sure you only count the number of trainable parameters."]},{"cell_type":"code","metadata":{"id":"XELONlQrrtm0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605746588905,"user_tz":300,"elapsed":201,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"742ee47a-61f4-4b5b-cf28-3268142da7fe"},"source":[" model = SequenceClassificationBERT(config=config, bert_model=bert_model)#.cuda()\n"," n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n"," print(n_parameters)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["109483778\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RHiacH7Hvnjx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605746589639,"user_tz":300,"elapsed":293,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"b066bcc9-ecaf-478e-e7a3-c487cb83af5f"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"gp6x_cKhsBJV"},"source":["Now we train the model. Please make sure to read the pdf instructions. When you report results in the pdf writeup, make sure you report the mean and std of >=3 runs with different random seeds. Consider using ```set_seed(some number)``` before the below cell, before each run.\n","\n","Make sure in each run, you're picking the best validation accuracy. We're using Trainer instead of the normal training loop which we have seen many many times earlier in the semester. In the trainer, we need to specify ```num_train_epochs``` (in ```training_args```) which we defined above. Please feel free to modify ```training_args``` such that:\n","- The learning rate is small (around 0.00001).\n","- Your model doesn't have large improments on validation accuracy anymore, at the end of training. The expected behavior is that the final validation accuracy won't be much better than chance.\n","\n","We provided part of an example log below, but you may be able to get better accuracy. Again, make sure this run corresponds to using an non-pretrained BERT."]},{"cell_type":"markdown","metadata":{"id":"I5rTvO4__k-J"},"source":["## 42"]},{"cell_type":"code","metadata":{"id":"W3Fm8zLfHIMo","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1605747474140,"user_tz":300,"elapsed":865535,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"61657583-87a3-43a9-f4e1-7e61a5af7bd5"},"source":["set_seed(42)\n","bert_model = AutoModel.from_config(config)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:20, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.708421</td>\n","      <td>0.692452</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.694728</td>\n","      <td>0.695153</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.704171</td>\n","      <td>0.693598</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.693069</td>\n","      <td>0.692413</td>\n","      <td>0.545126</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.692995</td>\n","      <td>0.696835</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.688232</td>\n","      <td>0.698018</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.672368</td>\n","      <td>0.782858</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.656443</td>\n","      <td>0.761393</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.617128</td>\n","      <td>0.781193</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.545369</td>\n","      <td>0.893387</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.537603</td>\n","      <td>0.975785</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.501868</td>\n","      <td>1.019612</td>\n","      <td>0.537906</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.455042</td>\n","      <td>1.070630</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.498236</td>\n","      <td>1.368991</td>\n","      <td>0.462094</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.441006</td>\n","      <td>1.085406</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.441326</td>\n","      <td>1.091961</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.390165</td>\n","      <td>1.111575</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.371616</td>\n","      <td>1.167585</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.379401</td>\n","      <td>1.254715</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.336409</td>\n","      <td>1.236771</td>\n","      <td>0.494585</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.347737</td>\n","      <td>1.212325</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.318331</td>\n","      <td>1.232476</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.289635</td>\n","      <td>1.245581</td>\n","      <td>0.509025</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.5270758122743683,\n"," 'eval_loss': 1.2445663213729858}"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"IgCCovsO_mjt"},"source":["## 24"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0Dj_OIHv970N","executionInfo":{"status":"ok","timestamp":1605748370333,"user_tz":300,"elapsed":872318,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"6c9dd359-7c18-4505-cc07-9e887f4a7bae"},"source":["set_seed(24)\n","bert_model = AutoModel.from_config(config)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:27, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.711972</td>\n","      <td>0.697299</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.694387</td>\n","      <td>0.700740</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.705091</td>\n","      <td>0.693803</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.694329</td>\n","      <td>0.694338</td>\n","      <td>0.516245</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.693012</td>\n","      <td>0.698363</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.689919</td>\n","      <td>0.699362</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.679380</td>\n","      <td>0.715458</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.683034</td>\n","      <td>0.714951</td>\n","      <td>0.512635</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.650236</td>\n","      <td>0.794580</td>\n","      <td>0.534296</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.603410</td>\n","      <td>0.868186</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.552400</td>\n","      <td>1.013473</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.517505</td>\n","      <td>1.027236</td>\n","      <td>0.527076</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.499299</td>\n","      <td>1.045857</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.523397</td>\n","      <td>1.148276</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.424522</td>\n","      <td>1.121335</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.426965</td>\n","      <td>1.167672</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.416121</td>\n","      <td>1.204561</td>\n","      <td>0.458484</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.361241</td>\n","      <td>1.410942</td>\n","      <td>0.462094</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.371910</td>\n","      <td>1.392149</td>\n","      <td>0.465704</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.342836</td>\n","      <td>1.310528</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.347594</td>\n","      <td>1.306395</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.308976</td>\n","      <td>1.326684</td>\n","      <td>0.483755</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.308745</td>\n","      <td>1.330076</td>\n","      <td>0.469314</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.48014440433212996,\n"," 'eval_loss': 1.3404982089996338}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"LjNMGXwc_nsE"},"source":["## 8"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"qbAcEp9K99E9","executionInfo":{"status":"ok","timestamp":1605749288483,"user_tz":300,"elapsed":871878,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"d7a3bc52-7afe-47d3-96ef-6fcd67951c96"},"source":["set_seed(8)\n","bert_model = AutoModel.from_config(config)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:26, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.708485</td>\n","      <td>0.691133</td>\n","      <td>0.523466</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.697991</td>\n","      <td>0.692811</td>\n","      <td>0.530686</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.705070</td>\n","      <td>0.692751</td>\n","      <td>0.505415</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.694345</td>\n","      <td>0.691099</td>\n","      <td>0.541516</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.693707</td>\n","      <td>0.696569</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.689026</td>\n","      <td>0.695940</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.672538</td>\n","      <td>0.779645</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.664241</td>\n","      <td>0.725711</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.622184</td>\n","      <td>0.791372</td>\n","      <td>0.487365</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.572173</td>\n","      <td>0.897318</td>\n","      <td>0.519856</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.583188</td>\n","      <td>0.911216</td>\n","      <td>0.490975</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.514937</td>\n","      <td>0.961520</td>\n","      <td>0.509025</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.479805</td>\n","      <td>1.039304</td>\n","      <td>0.458484</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.473925</td>\n","      <td>1.095241</td>\n","      <td>0.447653</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.430895</td>\n","      <td>1.095936</td>\n","      <td>0.494585</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.410979</td>\n","      <td>1.195643</td>\n","      <td>0.472924</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.394789</td>\n","      <td>1.216222</td>\n","      <td>0.447653</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.356806</td>\n","      <td>1.239001</td>\n","      <td>0.476534</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.360286</td>\n","      <td>1.323641</td>\n","      <td>0.458484</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.351450</td>\n","      <td>1.313602</td>\n","      <td>0.440433</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.342201</td>\n","      <td>1.304076</td>\n","      <td>0.498195</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.312732</td>\n","      <td>1.327114</td>\n","      <td>0.501805</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.290922</td>\n","      <td>1.340764</td>\n","      <td>0.480144</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.48736462093862815,\n"," 'eval_loss': 1.3477346897125244}"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"DK9lyxtN_o2d"},"source":["## mean and std"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0TEWb3A_qgr","executionInfo":{"status":"ok","timestamp":1605749485717,"user_tz":300,"elapsed":217,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"bd1b27ae-703b-422b-eaac-dd06a0e009f9"},"source":["print(torch.mean(torch.Tensor([0.534296, 0.545126, 0.541516])))\n","print(torch.std(torch.Tensor([0.534296, 0.545126, 0.541516])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.5403)\n","tensor(0.0055)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KWL5fqXdkkED"},"source":["### From pretrained BERT"]},{"cell_type":"markdown","metadata":{"id":"ej94TjTZzBTE"},"source":["Now, let's do the above experiments using a pretrained BERT!"]},{"cell_type":"markdown","metadata":{"id":"5XINTMIEyJQX"},"source":["TODO:\n","- Complete the following three lines such that ```tokenizer``` and ```config``` and ```bert_model``` corresponds to the ```model_name``` we defined in the above cells. \n","- IMPORTANT (different from the TODO a few cells above): make sure that the BERT model below loads the pretrained weights!"]},{"cell_type":"code","metadata":{"id":"No783Jh23S4K","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["a4bc9bc89df8471c882e44493dc1d52a","7468d4c6a2cb4a409dd8544d433b157b","e0056e179cae4b418016c1bd5beb02a5","51e31c61ea1943c2935b9dd0f7cd6ff8","3cc8d4d93d6c4aa9bc1fecb703b20d0a","9076a12a2ab54f39a5b0ff0f3fdc2234","f19ff059c6434a9fbf809ef302a93ad4","64951f215e4e455e9f7af46385f802fb"]},"executionInfo":{"status":"ok","timestamp":1605749576223,"user_tz":300,"elapsed":37069,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"944df0a6-8112-4219-f2e4-fba557ee95bd"},"source":["tokenizer =  AutoTokenizer.from_pretrained(model_name)\n","config = AutoConfig.from_pretrained(model_name)\n","bert_model = AutoModel.from_pretrained(model_name)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4bc9bc89df8471c882e44493dc1d52a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xfLG6_Rp3TEE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749576225,"user_tz":300,"elapsed":36331,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"ce4f0a37-0f7e-4bd1-90da-76da8d7b7a0b"},"source":["bert_model "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"bfVkYRgm3TM4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605749576226,"user_tz":300,"elapsed":34862,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"7da87579-f579-4a96-83b1-483b2a8f413f"},"source":["train_dataset = GlueDataset(data_args, tokenizer=tokenizer)\n","eval_dataset = GlueDataset(data_args, tokenizer=tokenizer, mode=\"dev\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/datasets/glue.py:77: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  FutureWarning,\n","/usr/local/lib/python3.6/dist-packages/transformers/data/processors/glue.py:521: FutureWarning: This processor will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING.format(\"processor\"), FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"FRcT8J4Fy1ii"},"source":["TODO:\n","- Similarly, we train the model. For more instructions, please see the TODO cells above (i.e., the TODO corresponding to training the model, when we're not loading weights into BERT), as well as the hw5 pdf."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LUCP5nLwCE_O","executionInfo":{"status":"ok","timestamp":1605749580643,"user_tz":300,"elapsed":238,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"e6d8ce3c-22a0-4816-9122-3e33b3ea86fe"},"source":["training_args = TrainingArguments(\n","    logging_steps=50, \n","    per_device_train_batch_size=32, \n","    per_device_eval_batch_size=64, \n","    save_steps=1000,\n","    evaluate_during_training=True,\n","    output_dir=\"./models_finetuned/rte\",\n","    overwrite_output_dir=True,\n","    do_train=True,\n","    do_eval=True,\n","    do_predict=True,\n","    learning_rate=0.00001,\n","    num_train_epochs=15,\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/training_args.py:347: FutureWarning: The `evaluate_during_training` argument is deprecated in favor of `evaluation_strategy` (which has more options)\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ez23RaTT_tXf"},"source":["## 42"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"St2jvIn1_Z89","executionInfo":{"status":"ok","timestamp":1605750460751,"user_tz":300,"elapsed":873922,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"d1500b76-31d0-42db-c82a-370371044a24"},"source":["set_seed(42)\n","bert_model = AutoModel.from_pretrained(model_name)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:28, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.686389</td>\n","      <td>0.684553</td>\n","      <td>0.559567</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.670287</td>\n","      <td>0.670023</td>\n","      <td>0.570397</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.622761</td>\n","      <td>0.659230</td>\n","      <td>0.620939</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.553903</td>\n","      <td>0.642895</td>\n","      <td>0.628159</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.508243</td>\n","      <td>0.641267</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.416489</td>\n","      <td>0.679882</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.346666</td>\n","      <td>0.686745</td>\n","      <td>0.653430</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.307039</td>\n","      <td>0.726719</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.248263</td>\n","      <td>0.753071</td>\n","      <td>0.664260</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.203019</td>\n","      <td>0.799487</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.177927</td>\n","      <td>0.836933</td>\n","      <td>0.667870</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.128554</td>\n","      <td>0.898246</td>\n","      <td>0.667870</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.131040</td>\n","      <td>0.916422</td>\n","      <td>0.678700</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.106841</td>\n","      <td>0.959750</td>\n","      <td>0.675090</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.081035</td>\n","      <td>1.006102</td>\n","      <td>0.682310</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.082334</td>\n","      <td>1.079817</td>\n","      <td>0.678700</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.078376</td>\n","      <td>1.133555</td>\n","      <td>0.675090</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.058253</td>\n","      <td>1.177463</td>\n","      <td>0.675090</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.052988</td>\n","      <td>1.218074</td>\n","      <td>0.671480</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.042108</td>\n","      <td>1.210123</td>\n","      <td>0.682310</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.046818</td>\n","      <td>1.256504</td>\n","      <td>0.685921</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.031527</td>\n","      <td>1.274024</td>\n","      <td>0.685921</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.038059</td>\n","      <td>1.283035</td>\n","      <td>0.685921</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.6859205776173285,\n"," 'eval_loss': 1.2835935354232788}"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"o4_OywrH_uhE"},"source":["##24"]},{"cell_type":"code","metadata":{"id":"d20jbJV3GjOk","colab":{"base_uri":"https://localhost:8080/","height":981},"executionInfo":{"status":"ok","timestamp":1605751475705,"user_tz":300,"elapsed":873964,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"420486c6-9c67-421b-ce9e-bf085dbfa23d"},"source":["set_seed(24)\n","bert_model = AutoModel.from_pretrained(model_name)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:28, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.691471</td>\n","      <td>0.695889</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.678123</td>\n","      <td>0.680650</td>\n","      <td>0.469314</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.624777</td>\n","      <td>0.670348</td>\n","      <td>0.465704</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.552973</td>\n","      <td>0.665055</td>\n","      <td>0.610108</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.503305</td>\n","      <td>0.677464</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.423359</td>\n","      <td>0.703280</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.350407</td>\n","      <td>0.728992</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.296667</td>\n","      <td>0.786738</td>\n","      <td>0.628159</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.231240</td>\n","      <td>0.831559</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.203385</td>\n","      <td>0.860789</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.182151</td>\n","      <td>0.898437</td>\n","      <td>0.653430</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.127578</td>\n","      <td>0.946239</td>\n","      <td>0.675090</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.118362</td>\n","      <td>1.019125</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.102738</td>\n","      <td>1.072690</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.073436</td>\n","      <td>1.117374</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.068831</td>\n","      <td>1.193668</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.058373</td>\n","      <td>1.241479</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.052129</td>\n","      <td>1.304107</td>\n","      <td>0.638989</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.041595</td>\n","      <td>1.349826</td>\n","      <td>0.635379</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.035539</td>\n","      <td>1.351281</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.033790</td>\n","      <td>1.385328</td>\n","      <td>0.653430</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.027856</td>\n","      <td>1.399657</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.022650</td>\n","      <td>1.423070</td>\n","      <td>0.646209</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0, 'eval_acc': 0.6498194945848376, 'eval_loss': 1.424788475036621}"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"markdown","metadata":{"id":"ocGjkzGX_vYY"},"source":["##8"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1YMwSrvM_apd","executionInfo":{"status":"ok","timestamp":1605752521502,"user_tz":300,"elapsed":873860,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"f3a32801-e8bb-4722-88d9-dde154b25e5d"},"source":["set_seed(8)\n","bert_model = AutoModel.from_pretrained(model_name)\n","model = SequenceClassificationBERT(config=config, bert_model=bert_model).cuda()\n","\n","def compute_metrics(p: EvalPrediction):\n","    preds = np.argmax(p.predictions, axis=1)\n","    return glue_compute_metrics(data_args.task_name, preds, p.label_ids)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics,\n",")\n","\n","trainer.train()\n","trainer.evaluate()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='1170' max='1170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1170/1170 14:28, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.694616</td>\n","      <td>0.690420</td>\n","      <td>0.537906</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.681444</td>\n","      <td>0.672727</td>\n","      <td>0.548736</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.635080</td>\n","      <td>0.660973</td>\n","      <td>0.631769</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.546747</td>\n","      <td>0.636755</td>\n","      <td>0.613718</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.501192</td>\n","      <td>0.665569</td>\n","      <td>0.642599</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.404401</td>\n","      <td>0.696847</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.340688</td>\n","      <td>0.708268</td>\n","      <td>0.671480</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.291041</td>\n","      <td>0.752996</td>\n","      <td>0.667870</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.240380</td>\n","      <td>0.788558</td>\n","      <td>0.667870</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.197941</td>\n","      <td>0.819956</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.179833</td>\n","      <td>0.895654</td>\n","      <td>0.678700</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.129317</td>\n","      <td>0.926605</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.138835</td>\n","      <td>0.971936</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.107234</td>\n","      <td>1.010119</td>\n","      <td>0.667870</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.092126</td>\n","      <td>1.052668</td>\n","      <td>0.646209</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.078549</td>\n","      <td>1.109527</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>850</td>\n","      <td>0.068767</td>\n","      <td>1.139435</td>\n","      <td>0.649819</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.071408</td>\n","      <td>1.178173</td>\n","      <td>0.660650</td>\n","    </tr>\n","    <tr>\n","      <td>950</td>\n","      <td>0.047327</td>\n","      <td>1.225042</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.050433</td>\n","      <td>1.236799</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.047594</td>\n","      <td>1.261578</td>\n","      <td>0.657040</td>\n","    </tr>\n","    <tr>\n","      <td>1100</td>\n","      <td>0.034771</td>\n","      <td>1.295153</td>\n","      <td>0.664260</td>\n","    </tr>\n","    <tr>\n","      <td>1150</td>\n","      <td>0.032737</td>\n","      <td>1.305631</td>\n","      <td>0.664260</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:66: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n","  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","        </style>\n","      \n","      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5/5 00:01]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["{'epoch': 15.0,\n"," 'eval_acc': 0.6642599277978339,\n"," 'eval_loss': 1.3025087118148804}"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"8CE2-Jkl_whs"},"source":["##mean and std"]},{"cell_type":"code","metadata":{"id":"M-NiyC9LINhI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605752533180,"user_tz":300,"elapsed":184,"user":{"displayName":"Zian Jiang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3giGC8uln-dfaug3tXobQadw_NO40QXY1eKW9=s64","userId":"12733475157097855231"}},"outputId":"8840ce2a-b3b4-4ea7-b28d-c9337eef4f1d"},"source":["print(torch.mean(torch.Tensor([0.685921, 0.675090, 0.678700])))\n","print(torch.std(torch.Tensor([0.685921, 0.675090, 0.678700])))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.6799)\n","tensor(0.0055)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jm9tw989Ty_I"},"source":[""],"execution_count":null,"outputs":[]}]}